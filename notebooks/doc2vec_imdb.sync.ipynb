{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcbd333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 17:19:12.785280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 17:19:12.938275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-06 17:19:12.938293: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-06 17:19:12.964711: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-06 17:19:13.553264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 17:19:13.553320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 17:19:13.553326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "import transformer_document_embedding as tde\n",
    "\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ac9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tde = importlib.reload(tde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d3f1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 17:19:15,318 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d400,n5,mc5,s0.001,t12>', 'datetime': '2023-02-06T17:19:15.318647', 'gensim': '4.2.0', 'python': '3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]', 'platform': 'Linux-6.0.11-1-MANJARO-x86_64-with-glibc2.36', 'event': 'created'}\n",
      "2023-02-06 17:19:15.338274: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-02-06 17:19:15.338303: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: manjaro-pc\n",
      "2023-02-06 17:19:15.338309: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: manjaro-pc\n",
      "2023-02-06 17:19:15.338409: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.60.11\n",
      "2023-02-06 17:19:15.338425: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.60.11\n",
      "2023-02-06 17:19:15.338430: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.60.11\n",
      "2023-02-06 17:19:15.338704: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"../results/notebooks/doc2vec_imdb\"\n",
    "task = tde.tasks.IMDBClassification(data_size_limit=100)\n",
    "model = tde.models.Doc2VecIMDB(log_dir=LOG_DIR, use_dm=False, dbow_kwargs={\"epochs\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5829b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 17:19:18,608 : WARNING : Found cached dataset imdb (/home/dburian/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "2023-02-06 17:19:18,624 : WARNING : Loading cached processed dataset at /home/dburian/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-6c9a401648fa09b0.arrow\n",
      "2023-02-06 17:19:20,904 : WARNING : Found cached dataset imdb (/home/dburian/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "2023-02-06 17:19:20,918 : WARNING : Loading cached processed dataset at /home/dburian/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-9ef2174596950ddb.arrow\n",
      "2023-02-06 17:19:23,151 : WARNING : Found cached dataset imdb (/home/dburian/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "2023-02-06 17:19:23,163 : WARNING : Loading cached processed dataset at /home/dburian/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-9a08b03fbbbf76fd.arrow\n",
      "2023-02-06 17:19:23,190 : INFO : collecting all words and their counts\n",
      "2023-02-06 17:19:23,191 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-02-06 17:19:23,223 : INFO : collected 13861 word types and 300 unique tags from a corpus of 300 examples and 66759 words\n",
      "2023-02-06 17:19:23,223 : INFO : Creating a fresh vocabulary\n",
      "2023-02-06 17:19:23,230 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1531 unique words (11.05% of original 13861, drops 12330)', 'datetime': '2023-02-06T17:19:23.230652', 'gensim': '4.2.0', 'python': '3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]', 'platform': 'Linux-6.0.11-1-MANJARO-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2023-02-06 17:19:23,231 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49563 word corpus (74.24% of original 66759, drops 17196)', 'datetime': '2023-02-06T17:19:23.231142', 'gensim': '4.2.0', 'python': '3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]', 'platform': 'Linux-6.0.11-1-MANJARO-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2023-02-06 17:19:23,238 : INFO : deleting the raw counts dictionary of 13861 items\n",
      "2023-02-06 17:19:23,239 : INFO : sample=0.001 downsamples 54 most-common words\n",
      "2023-02-06 17:19:23,239 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 33635.14244245144 word corpus (67.9%% of prior 49563)', 'datetime': '2023-02-06T17:19:23.239668', 'gensim': '4.2.0', 'python': '3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]', 'platform': 'Linux-6.0.11-1-MANJARO-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2023-02-06 17:19:23,251 : INFO : estimated required memory for 1531 words and 400 dimensions: 6204700 bytes\n",
      "2023-02-06 17:19:23,251 : INFO : resetting layer weights\n",
      "2023-02-06 17:19:23,254 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 12 workers on 1531 vocabulary and 400 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-06T17:19:23.254942', 'gensim': '4.2.0', 'python': '3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]', 'platform': 'Linux-6.0.11-1-MANJARO-x86_64-with-glibc2.36', 'event': 'train'}\n",
      "2023-02-06 17:19:23,310 : INFO : EPOCH 0: training on 66759 raw words (33954 effective words) took 0.1s, 641365 effective words/s\n",
      "2023-02-06 17:19:23,311 : INFO : Doc2Vec lifecycle event {'msg': 'training on 66759 raw words (33954 effective words) took 0.1s, 608609 effective words/s', 'datetime': '2023-02-06T17:19:23.311228', 'gensim': '4.2.0', 'python': '3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]', 'platform': 'Linux-6.0.11-1-MANJARO-x86_64-with-glibc2.36', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "doc2vec_train = datasets.combine.concatenate_datasets(\n",
    "    [task.train, task.unsupervised, task.test]\n",
    ")\n",
    "doc2vec_train = doc2vec_train.shuffle()\n",
    "model._doc2vec.train(doc2vec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca895bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = model._cls_head_dataset(task.train, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35400c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ds = task.train.to_tf_dataset(1, columns=[\"label\"]).unbatch()\n",
    "list(label_ds.take(4).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e17f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.zip((ds, label_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583b5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.shuffle(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db4d7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8486d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[[ 0.00383041, -0.00374159,  0.00129179, ...,  0.00068196,\n",
       "           -0.00339289,  0.00224405],\n",
       "          [ 0.00115191, -0.00145747,  0.00225265, ...,  0.00255739,\n",
       "           -0.00455078, -0.00104928]],\n",
       "  \n",
       "         [[ 0.00853373, -0.00368737, -0.00121163, ...,  0.00374191,\n",
       "           -0.00892638,  0.00246742],\n",
       "          [ 0.01140269, -0.00852688, -0.00101106, ...,  0.00386177,\n",
       "           -0.01037293,  0.00100791]]], dtype=float32),\n",
       "  array([0, 0])),\n",
       " (array([[[ 7.5155258e-02, -5.2878477e-02, -1.8147372e-03, ...,\n",
       "            2.6095346e-02, -9.1855139e-02,  1.0356689e-02],\n",
       "          [ 5.5019073e-03, -6.7298990e-03,  9.7220829e-05, ...,\n",
       "            8.4743573e-04, -9.0664644e-03,  4.1881960e-04]],\n",
       "  \n",
       "         [[ 2.3298461e-02, -1.7067494e-02, -1.1242531e-03, ...,\n",
       "            5.2597229e-03, -2.7863495e-02,  1.1197915e-03],\n",
       "          [ 6.8207242e-02, -4.6731599e-02, -4.4107218e-03, ...,\n",
       "            2.4513312e-02, -8.1739172e-02,  8.0103669e-03]]], dtype=float32),\n",
       "  array([0, 0])),\n",
       " (array([[[ 0.01236301, -0.01214072, -0.00026625, ...,  0.00779697,\n",
       "           -0.01993977,  0.00307858],\n",
       "          [ 0.06736329, -0.04512239, -0.00284185, ...,  0.02321954,\n",
       "           -0.07984611,  0.00807284]],\n",
       "  \n",
       "         [[ 0.02361615, -0.01674264, -0.00283356, ...,  0.00667   ,\n",
       "           -0.03016073,  0.00198565],\n",
       "          [ 0.01471094, -0.01368588, -0.00283819, ...,  0.00586487,\n",
       "           -0.0217116 ,  0.00058274]]], dtype=float32),\n",
       "  array([0, 0])),\n",
       " (array([[[ 0.032136  , -0.02295634, -0.00182103, ...,  0.01008234,\n",
       "           -0.03639193,  0.00345664],\n",
       "          [ 0.06311877, -0.04303826, -0.00498007, ...,  0.0244876 ,\n",
       "           -0.0790189 ,  0.01123384]],\n",
       "  \n",
       "         [[ 0.10729657, -0.07414857, -0.00420633, ...,  0.03815033,\n",
       "           -0.13267307,  0.01612004],\n",
       "          [ 0.00892202, -0.00510735,  0.00089423, ...,  0.00287025,\n",
       "           -0.01069102, -0.00110218]]], dtype=float32),\n",
       "  array([0, 0]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ds.take(4).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94996757",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UnbatchDataset' object has no attribute 'isidentifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cls_head_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/docs/transformer_document_embedding/src/transformer_document_embedding/models/doc2vec_imdb.py:115\u001b[0m, in \u001b[0;36mDoc2VecIMDB._cls_head_dataset\u001b[0;34m(self, data, training)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m    114\u001b[0m     labels_ds \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_tf_dataset(\u001b[38;5;241m1\u001b[39m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39munbatch()\n\u001b[0;32m--> 115\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m25000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;28;01melse\u001b[39;00m ds\n\u001b[1;32m    118\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cls_head\u001b[38;5;241m.\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/.local/share/python-venvs/diploma_thesis/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:1264\u001b[0m, in \u001b[0;36mDatasetV2.zip\u001b[0;34m(datasets, name)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzip\u001b[39m(datasets, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1220\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` by zipping together the given datasets.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \n\u001b[1;32m   1222\u001b[0m \u001b[38;5;124;03m  This method has similar semantics to the built-in `zip()` function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mZipDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/python-venvs/diploma_thesis/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:4856\u001b[0m, in \u001b[0;36mZipDataset.__init__\u001b[0;34m(self, datasets, name)\u001b[0m\n\u001b[1;32m   4850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   4851\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets,\n\u001b[1;32m   4852\u001b[0m     [ds\u001b[38;5;241m.\u001b[39melement_spec \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets)])\n\u001b[1;32m   4853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m   4854\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mzip_dataset(\n\u001b[1;32m   4855\u001b[0m     [ds\u001b[38;5;241m.\u001b[39m_variant_tensor \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets)],\n\u001b[0;32m-> 4856\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_args\u001b[49m)\n\u001b[1;32m   4857\u001b[0m \u001b[38;5;28msuper\u001b[39m(ZipDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[0;32m~/.local/share/python-venvs/diploma_thesis/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:688\u001b[0m, in \u001b[0;36mDatasetV2._common_args\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_common_args\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m   \u001b[38;5;124;03m\"\"\"Helper for generating arguments that are common across most dataset ops.\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \n\u001b[1;32m    676\u001b[0m \u001b[38;5;124;03m  Most dataset op constructors expect `output_shapes` and `output_types`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m    constructor.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    687\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 688\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[38;5;241m.\u001b[39mSerializeToString(),\n\u001b[1;32m    689\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_shapes,\n\u001b[1;32m    690\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_types\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_types,\n\u001b[1;32m    691\u001b[0m   }\n",
      "File \u001b[0;32m~/.local/share/python-venvs/diploma_thesis/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:669\u001b[0m, in \u001b[0;36mDatasetV2._metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name:\n\u001b[0;32m--> 669\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_and_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "File \u001b[0;32m~/.local/share/python-venvs/diploma_thesis/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:119\u001b[0m, in \u001b[0;36m_validate_and_encode\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_and_encode\u001b[39m(name):\n\u001b[0;32m--> 119\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misidentifier\u001b[49m():\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `name`. The argument `name` needs to be a valid \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentifier. Value is considered a valid identifier if it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly contains alphanumeric characters (a-z), (A-Z), and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(0-9), or underscores (_). A valid identifier cannot \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart with a number, or contain any spaces.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m name\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_UnbatchDataset' object has no attribute 'isidentifier'"
     ]
    }
   ],
   "source": [
    "ds = model._cls_head_dataset(task.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

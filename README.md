[./d/related_work]: ./doc/related_work.md
[d/timeline]: doc/timeline.md
[d/approach]: doc/approach.md
[d/datasets]: doc/datasets.md
[awesome_ir]: https://github.com/harpribot/awesome-information-retrieval
[google_doc_topic]: https://docs.google.com/document/d/13Yb34eyklpX6bGzaf3m0jlsFb8rF10KvLXh4DuY4SD0/edit#heading=h.k2zhq4p261n
[sbert]: https://arxiv.org/abs/1908.10084
[longformer]: https://arxiv.org/pdf/2004.05150v2.pdf
[reformer]: https://arxiv.org/pdf/2001.04451.pdf
[jian_22]: https://arxiv.org/pdf/2209.09433.pdf
[xiong_21]: https://arxiv.org/pdf/2112.07210.pdf
[luo_21]: https://arxiv.org/pdf/2103.14542.pdf
[awesome_ds]: https://github.com/malteos/awesome-document-similarity
[medic_22]: https://arxiv.org/pdf/2209.05452.pdf
[xiong_20]: https://arxiv.org/abs/2007.00808
[ir_datasets]: https://ir-datasets.com/index.html

# Diploma thesis

## TOC

- [Datasets info][d/datasets]
- [Approach][d/approach]
- [Timeline][d/timeline]
- [Related work][./d/related_work] - collection of articles that might be useful
  in the future


## Links

- [Finalized topic](https://is.cuni.cz/studium/dipl_st/index.php?id=a91fb39f906ae7e035142a978450e151&tid=1&do=main&doo=detail&did=250786)


## Helpful sources

- [SBERT][sbert]
- [Longformer][longformer]
- [Reformer][reformer]

- [Contrastive learning of Sent. embed. using non-linguistic
  modalities][jian_22]

- current state-of-the-art sentence embeddings:

Tianyu Gao, Xingcheng Yao, and Danqi Chen. SimCSE: Simple contrastive learning
of sentence embeddings. In Empirical Methods in Natural Language Processing
(EMNLP), 2021.

- [comparison of attention types for longer documents][xiong_21]
- [Unsupervised Document Embedding via Contrastive Augmentation - 21 with
  doc2vecC as backbone][luo_21]

- [Awesome document similarity site][awesome_ds] covers all from methodology,
  models to benchmarks
- [Awesome information retrieval][awesome_ir]


- [Testing article encoders for recommendation][medic_22]
- [Contrative learning for Dense Representations][xiong_20]

- [IR datasets python package][ir_datasets]


## Interesting snippets

- [Jian 2022][jian_22]:

> "we show that Transformer models can generalize better by learning a similar
> task (i.e., clustering) with multi-task losses using non-parallel examples
> from different modalities."


- [CSDCube][mysore_21]:

> The dominant paradigm of information retrieval is to treat queries and
> documents as different kinds of objects, e.g., in keyword search. This
> paradigm, however, does not lend itself to exploratory search tasks. On the
> other hand, paradigms of search such Query by Example (QBE) which treat
> queries and documents as similar kinds of objects have been considered more
> suited to exploratory search tasks [41, 17, 45].

model:
  module: paragraph_vector.embed:ParagraphVectorEmbed
  kwargs:
    dm_kwargs: null
    dbow_kwargs:
      epochs: 1
      max_vocab_size: 6.0e+7 # ~60GBs of memory
      workers: 8
  train_kwargs:
    start_at_epoch: null
    save_at_epochs: [0, 3, 7]
    stem: False
    lowercase: False
    num_proc: 12

task:
  module: teacher_embedding:TeacherEmbedding
  kwargs:
    path: /mnt/data/datasets/wikipedia_sample_with_eval
    data_size_limit:
      train: 100
      validation: 50

tde_version: 0.0.2
model:
  module: longformer.student:LongformerStudent
  kwargs:
    large: False
    batch_size: 3
    pooler_type: mean
    static_loss_kwargs: null
    contextual_max_length: 384
    contextual_loss_kwargs:
      contextual_key: sbert
      lam: 1
      contextual_loss_type: cos_dist

  train_kwargs:
    dataloader_sampling: consistent
    bucket_limits: [384]
    grad_accumulation_steps: 16
    learning_rate: 3.0e-5
    weight_decay: 1.0e-2
    warmup_steps: 2
    epochs: 1
    early_stopping: False
    save_best: False
    log_every_step: 4
    validate_every_step: 16

task:
  module: teacher_embedding:TeacherEmbedding
  kwargs:
    path: /mnt/data/datasets/wikipedia_sample_with_eval
    data_size_limit:
      validation: 12
      # train: 4200
      train: 102
